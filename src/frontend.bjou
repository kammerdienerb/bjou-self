# frontend.bjou

module frontend

using import "measure_time.bjou"
using import "thread.bjou"
using import "threadpool.bjou"
using import "bucket_array.bjou"
using import "io.bjou"
using import "hash_table.bjou"
using import "hash_set.bjou"
using import "pair.bjou"


using import "globals.bjou"
using import "compilation.bjou"
using import "ast.bjou"
using import "utils.bjou"
using import "parser.bjou"
using import "hash_functions.bjou"
using import "scope.bjou"
using import "ty.bjou"
using import "ui.bjou"
using import "digraph.bjou"


type async_module_scope_info {
    idx   : i32
    nodes : astref[...] # copied, not owned
    fe    : frontend ref
}


enum phases {
    NONE,
    PARSING,
    SYMBOLS,
    TYPES
}

type frontend {
    phase              : phases
    n_files            : u64
    n_lines            : u64
    n_blank_lines      : u64
    n_bytes            : u64
    pool               : (threadpool ref | none)
    all_nodes          : bucket_array$ast
    top_level_nodes    : bucket_array$astref
    include_containers : bucket_array$include_container
    files_seen         : hash_set$(string, str_hasher)
    global_scope       : globalscope
    all_subscopes      : bucket_array$scope
    type_nodes         : bucket_array$astref
    # @bug 9 @bug 13
    # Shouldn't have to qualify the ty module here.
    type_table         : hash_table$(string, ty::ty, str_hasher)
    using_scope_list   : pair$(ast ref, scope*)[...]

    merge_lock             : mutex
    include_container_lock : mutex
    files_seen_lock        : mutex
    global_scope_lock      : mutex
    alloc_subscope_lock    : mutex
    using_scope_list_lock  : mutex


    proc create() : frontend {
        return { frontend:
            .phase                  = phases.NONE,
            .all_nodes              = bucket_array$ast.create(),
            .include_containers     = bucket_array$include_container.create(),
            .top_level_nodes        = bucket_array$astref.create(),
            .files_seen             = hash_set$(string, str_hasher).create(),
            .global_scope           = globalscope.create(),
            .all_subscopes          = bucket_array$scope.create(),
            .type_nodes             = bucket_array$astref.create(),
            .type_table             = hash_table$(string, ty, str_hasher).create(),
            .using_scope_list       = [...pair$(ast ref, scope*)],
            .merge_lock             = mutex.create(),
            .include_container_lock = mutex.create(),
            .files_seen_lock        = mutex.create(),
            .global_scope_lock      = mutex.create(),
            .alloc_subscope_lock    = mutex.create(),
            .using_scope_list_lock  = mutex.create(),
        }
    }

    proc go(this) {
        beg := measure_time_now_ms()

        if not compil.args.no_parallel {
            n_threads := compil.args.threads
            if n_threads == 0
                n_threads = 1
            else if n_threads <= -1
                n_threads = thread::hw_threads() - 1

            this.pool = threadpool.create(n_threads)
        }

        # do work
        install_builtin_types(this.type_table)

        this.do_parsing()
        if compil.args.syntax_only {
            return
        }

        this.do_symbols()
#         this.do_type_table()

        if pool : threadpool ref = this.pool {
            pool.stop(stopmode.GRACEFUL)
            pool.free()
        }

        end := measure_time_now_ms()

        if compil.args.stats {
            using ui
            ms := end - beg
            report_phase_time("Front-end", ms, Attr.GREEN)
        }
    }

    proc do_parsing(this) {
        this.phase = phases.PARSING

        parse_beg := measure_time_now_ms()
        if pool : threadpool ref = this.pool {
            this.parse_parallel(pool)
        } else {
            this.parse_serial()
        }
        parse_end := measure_time_now_ms()

        if compil.args.stats {
            using ui
            ms := parse_end - parse_beg
            phase_str := str("Parsed ")
            phase_str  = concat(phase_str, str(this.n_files), str(" files"))
            report_phase_time(phase_str.c_str(), ms, Attr.YELLOW)
            phase_str.free()
        }

        s := str("total number of nodes is ") + str(this.all_nodes.len())
        info_builder.create().with_message(s.c_str()).report().free()
        s.free()
        s = str("number of top-level nodes is ") + str(this.top_level_nodes.len())
        info_builder.create().with_message(s.c_str()).report().free()
        s.free()
    }

    proc parse_serial(this) {
        foreach ref path in compil.args.input {
            f        := open_file(path, search_paths: false)
            new_path := str(f.path)

            if stored_path : string ref = this.first_encounter_of_file(new_path) {
                p := parser.create(this, stored_path, f, kind: parserkind.IMPORT)
                p.scope_stack.push(&this.global_scope)
                p.go()
            } else {
                input_repeat_error(path)
            }

            new_path.free()
        }
    }

    proc parse_parallel(this, pool : threadpool ref) {
        foreach ref path in compil.args.input {
            f        := open_file(path, search_paths: false)
            new_path := str(f.path)


            if stored_path : string ref = this.first_encounter_of_file_locked(new_path) {
                p := new async_parser
                @p = async_parser.create(this, pool, stored_path, f, kind: parserkind.INPUT_FILE)
                p.scope_stack.push(&this.global_scope)
                pool.add_task(async_parser_wrapper, p)
            } else {
                input_repeat_error(path)
            }

            new_path.free()
        }

        pool.wait()
    }

    proc do_symbols(this) {
        this.phase = phases.SYMBOLS

        symbols_beg := measure_time_now_ms()

        # @incomplete
        # Once we have a type system in place and working, we need to
        # verify that all procs in overload sets have unique signatures.
        #
        # Actually, maybe this should be done on the fly also as we type-check
        # everything.

        this.resolve_identifiers()

        symbols_end := measure_time_now_ms()

        if compil.args.dump_symbols {
            this.global_scope.show()
        }

        if compil.args.stats {
            using ui
            ms := symbols_end - symbols_beg
            report_phase_time("Populated symbol tables", ms, Attr.YELLOW)
        }

    }

    proc resolve_identifiers(this) {
        for it := this.all_nodes.iter(); not it.is_end(); it.next() {
            if qid : qidentifier = it.val() {
                resolve_identifier(qid)
            }
        }
    }

    proc do_type_table(this) {
        this.phase = phases.TYPES

        types_beg := measure_time_now_ms()

        # @performance
        # Can/should we parallelize this step somehow?

        # Make an entry in the table for every type.
        # Pre-pass to insert the ty types before filling them out.
        for it := this.type_nodes.iter(); not it.is_end(); it.next() {
            # @unsafe
            # This node must be valid because it is added to the bucket
            # array in a block that requires it to be valid.
            # See add_single_node_to_top_level_scope() and friends.
            node := unsafe_ast_ref(it.val())

            if decl : declaration = node {
                this.add_to_type_table(node)
            }
        }

        # Now go back through and complete them.
        for it := this.type_nodes.iter(); not it.is_end(); it.next() {
            # @unsafe
            # This node must be valid because it is added to the bucket
            # array in a block that requires it to be valid.
            # See add_single_node_to_top_level_scope() and friends.
            node := unsafe_ast_ref(it.val())

            this.complete_type(node)
        }

        types_end := measure_time_now_ms()

        if compil.args.stats {
            using ui
            ms := types_end - types_beg
            report_phase_time("Completed types", ms, Attr.YELLOW)
        }
    }

    proc add_to_type_table(this, node : ast ref) {
        t : ty = { tyunknown: }

        if        td  : typedef = node {
            t = { tystruct: }
        } else if ttd : templatetypedef = node {
            t = { tytemplatestruct: }
        } else if e   : enumdef = node {
            t = { tyenum: }
        }

        if decl : declaration = node {
            this.type_table.insert(decl.name, t)
        }
    }

    proc complete_type(this, node : ast ref) {
        if decl : declaration = node {
            m_pair := this.type_table.lookup(decl.name)
            if key_val : pair$(string ref, ty ref) = m_pair {
                if        ts : tystruct = key_val.second {
                    key_val.second = tystruct.create_from_node(node)
                } else if tt : tytemplatestruct = key_val.second {
                    key_val.second = tytemplatestruct.create_from_node(node)
                } else if te : tyenum = key_val.second {
                    key_val.second = tyenum.create_from_node(node)
                }
            } else {
                debug_assert(false, "type not in type table")
            }
        } else {
            debug_assert(false, "node is not a delcaration")
        }
    }

    proc total_lines(this) : u64
        return this.n_lines

    proc code_lines(this) : u64
        return this.n_lines - this.n_blank_lines

    proc __inline__ add_new_module_scope_locked(this, name : string ref) : i32 {
        this.global_scope_lock.lock()
            idx := this._add_new_module_scope(name)
        this.global_scope_lock.unlock()
        return idx
    }

    proc __inline__ add_new_module_scope(this, name : string ref) : i32 {
        return this._add_new_module_scope(name)
    }

    proc _add_new_module_scope(this, name : string ref) : i32 {
        return this.global_scope.get_or_add_module_scope_idx(name)
    }


    proc __inline__ get_next_include_container_locked(this) : include_container ref {
        this.include_container_lock.lock()
            r := this._get_next_include_container()
        this.include_container_lock.unlock()
        return r
    }

    proc __inline__ get_next_include_container(this) : include_container ref {
        return this._get_next_include_container()
    }

    proc _get_next_include_container(this) : include_container ref {
        ic := { include_container:
            .nodes = bucket_array$astref.create(),
            .lock  = thread::mutex.create()
        }
        return this.include_containers.push(ic)
    }


    proc __inline__ first_encounter_of_file_locked(this, path : string ref) : (string ref | none) {
        this.files_seen_lock.lock()
            r := this._first_encounter_of_file(path)
        this.files_seen_lock.unlock()
        return r
    }

    proc __inline__ first_encounter_of_file(this, path : string ref) : (string ref | none) {
        return this._first_encounter_of_file(path)
    }

    proc _first_encounter_of_file(this, path : string ref) : (string ref | none) {
        search := this.files_seen.lookup(path)

        if search.is_none() {
            return this.files_seen.insert(path.copy())
        }

        return nothing
    }

    proc visit_all(this, visitor : visitor_t, arg : void*) {
        for it := this.top_level_nodes.iter(); not it.is_end(); it.next() {
            m_node := it.val()
            if node : ast ref = m_node {
                if visit(node, visitor, arg) == visit_action.BREAK {
                    break
                }
            }
        }
    }

    proc add_using_scope_pair(this, u : ast ref, s : scope*) {
        this.using_scope_list_lock.lock()
            p := pair$(ast ref, scope*).create(u, s)
            this.using_scope_list.push(p)
        this.using_scope_list_lock.unlock()
    }
}

proc fe_alloc_sub_scope(sub : scope) : scope ref {
    fe := getref(compil.front)

    if pool : threadpool ref = fe.pool {
        fe.alloc_subscope_lock.lock()
            scope_ref := getref(fe.all_subscopes.push(sub))
        fe.alloc_subscope_lock.unlock()

        return scope_ref
    }

    return fe.all_subscopes.push(sub)
}

proc filter_scopes_from_bucket_array(nodes : bucket_array$astref ref, procs : astref[...] ref) {
    for it := nodes.iter(); not it.is_end(); it.next() {
        if node : ast ref = it.val() {
            if unsafe_baseref(node).get_flag(ast_flag.OPENS_SCOPE) {
                procs.push(node)
            } else if t : typedef = node {
                foreach d in t.declarations {
                    if p : procdef = unsafe_ast_ref(d) {
                        procs.push(d)
                    }
                }
            } else if i : includestmt = node    {
                if ic : include_container ref = i.container {
                    filter_scopes_from_bucket_array(ic.nodes, procs)
                }
            }
        } else debug_assert(false, "bad node in filter_scopes_from_bucket_array")
    }
}

proc __inline__ open_file(path : string ref, search_paths : bool) : file {
    return open_file(path, search_paths, nothing)
}
proc open_file(path : string ref, search_paths : bool, from_cxt : (context ref | none)) : file {
    f : (file | none) = nothing

    if search_paths { f = search_for_file_and_open(path)     }
    else            { f = file.open(path.c_str(), file.READ) }

    if f' : file = f {
        if not f'.good() {
            open_file_error(path, from_cxt)
        }
        return f'
    }

    open_file_error(path, from_cxt)

    return { file: }
}

proc search_for_file_and_open(path : string ref) : (file | none) {
    foreach ref prefix in compil.search_paths {
        path' := prefix.copy()
        path'.append(path)
        f     := io::file.open(path'.c_str(), file.READ)
        path'.free()

        if f.good() { return f }
    }

    return nothing
}

proc open_file_error(path : string ref, from_cxt : (context ref | none)) {
    err_str := str("Unable to read file '")
    err_str.append(path)
    err_str.append("'.")

    eb := error_builder.create()
        .with_message(err_str.c_str())

    if cxt : context ref = from_cxt {
        eb = eb.add_location(cxt)
    }

    eb.report()
}

proc input_repeat_error(path : string ref) {
    err_str := str("File '")
    err_str.append(path)
    err_str.append("' is repeated in the input file list.")

    error(err_str.c_str())
}

proc multiple_include_error(path : string ref, intro_cxt : context ref) {
    err_str := str("File '")
    err_str.append(path)
    err_str.append("' has already been encountered and may not be included again.")

    error_builder.create()
        .with_message(err_str.c_str())
        .add_location(intro_cxt)
        .report()
}
